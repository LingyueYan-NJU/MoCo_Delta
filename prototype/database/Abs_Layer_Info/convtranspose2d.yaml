api: convtranspose2d
constraints:
  bias:
    default: true
    descp: If True, adds a learnable bias to the output.
    dtype: torch.bool
  dilation:
    default: 1
    descp: Spacing between kernel elements.
    dtype: int
    range:
    - 1
    - 6
    shape: 2
    structure:
    - integer
    - tuple
  groups:
    default: 1
    descp: Number of blocked connections from input channels to output channels.
    dtype: int
    range:
    - 1
    - 3
    shape: 1
    structure:
    - integer
  in_channels:
    descp: Number of channels in the input image
    dtype: int
    range:
    - 1
    - 512
    shape: 1
    structure:
    - integer
  kernel_size:
    descp: Size of the convolving kernel
    dtype: int
    range:
    - 1
    - 8
    shape: 2
    structure:
    - integer
    - tuple
  out_channels:
    descp: Number of channels produced by the convolution
    dtype: int
    range:
    - 1
    - 42024
    shape: 1
    structure:
    - integer
  output_padding:
    default: 0
    descp: Additional size added to one side of each dimension in the output shape.
    dtype: int
    range:
    - 1
    - 8
    shape: 2
    structure:
    - integer
    - tuple
  padding:
    default: 0
    descp: dilation zero-padding will be added to both sides of each dimension in
      the input.
    dtype: int
    range:
    - 1
    - 8
    shape: 2
    structure:
    - integer
    - tuple
  stride:
    default: 1
    descp: Stride of the convolution.
    dtype: int
    range:
    - 1
    - 4
    shape: 2
    structure:
    - integer
    - tuple
descp: Applies a 2D transposed convolution operator over an input image composed of
  several input planes.
inputs:
  optional:
  - stride
  - padding
  - output_padding
  - groups
  - bias
  - dilation
  required:
  - in_channels
  - out_channels
  - kernel_size
