api: torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0,
  dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
constraints:
  bias:
    default: true
    descp: If True, adds a learnable bias to the output.
    dtype: torch.bool
  dilation:
    default: 1
    descp: Spacing between kernel elements.
    dtype: int
    range:
    - 1
    - 6
    shape: 3
    structure:
    - integer
    - tuple
  groups:
    default: 1
    descp: Number of blocked connections from input channels to output channels.
    dtype: int
    range:
    - 1
    - 3
    shape: 1
    structure:
    - integer
  in_channels:
    descp: Number of channels in the input image
    dtype: int
    range:
    - 1
    - 12544
    shape: 1
    structure:
    - integer
  kernel_size:
    descp: Size of the convolving kernel
    dtype: int
    range:
    - 1
    - 8
    shape: 3
    structure:
    - integer
    - tuple
  out_channels:
    descp: Number of channels produced by the convolution
    dtype: int
    range:
    - 1
    - 512
    shape: 1
    structure:
    - integer
  padding:
    default: 0
    descp: Padding added to all six sides of the input.
    dtype:
    - int
    - torch.string
    enum:
    - same
    - valid
    range:
    - 1
    - 8
    shape: 3
    structure:
    - integer
    - tuple
  padding_mode:
    default: zeros
    descp: '''zeros'', ''reflect'', ''replicate'' or ''circular''.'
    dtype: torch.string
    enum:
    - zeros
    - reflect
    - replicate
    - circular
  stride:
    default: 1
    descp: Stride of the convolution.
    dtype: int
    range:
    - 1
    - 4
    shape: 3
    structure:
    - integer
    - tuple
descp: Applies a 3D convolution over an input signal composed of several input planes.
inputs:
  optional:
  - stride
  - padding
  - dilation
  - groups
  - bias
  - padding_mode
  required:
  - in_channels
  - out_channels
  - kernel_size
