api: paddle.nn.Embedding
constraints:
  embedding_dim:
    default: null
    descp: Just one element which indicate the size of each embedding vector respectively
    dtype:
    - int
    enum: null
    range: null
    shape: null
    structure:
    - int
  name:
    default: None
    descp: For detailed information, please refer to Name. Usually name is no need
      to set and None by default
    dtype:
    - str
    - int
    enum:
    - need
    - need
    - need
    - need
    range: null
    shape: null
    structure:
    - str
    - None
  num_embeddings:
    default: null
    descp: Just one element which indicate the size of the dictionary of embeddings
    dtype:
    - int
    enum: null
    range: null
    shape: null
    structure:
    - int
  padding_idx:
    default: None
    descp: 'padding_idx needs to be in the interval [-num_embeddings, num_embeddings).
      If \(padding\_idx < 0\), the \(padding\_idx\) will automatically be converted
      to \(vocab\_size + padding\_idx\) . It will output all-zero padding data whenever
      lookup encounters \(padding\_idx\) in id. And the padding data will not be updated
      while training. If set None, it makes no effect to output. Default: None'
    dtype:
    - int
    - long
    - None
    enum: null
    range: null
    shape: null
    structure:
    - int
    - long
    - None
  sparse:
    default: 'False'
    descp: 'The flag indicating whether to use sparse update. This parameter only
      affects the performance of the backwards gradient update. It is recommended
      to set True because sparse update is faster. But some optimizer does not support
      sparse update, such as api_paddle_optimizer_adadelta_Adadelta , api_paddle_optimizer_adamax_Adamax
      , api_paddle_optimizer_lamb_Lamb. In these case, sparse must be False. Default:
      False'
    dtype:
    - bool
    enum: null
    range: null
    shape: null
    structure:
    - bool
  weight_attr:
    default: None
    descp: 'To specify the weight parameter property. Default: None, which means the
      default weight parameter property is used. See usage for details in api_ParamAttr
      . In addition, user-defined or pre-trained word vectors can be loaded with the
      param_attr parameter. The local word vector needs to be transformed into numpy
      format, and the shape of local word vector should be consistent with num_embeddings
      . Then api_initializer_NumpyArrayInitializer is used to load custom or pre-trained
      word vectors. See code example for details'
    dtype:
    - ParamAttr
    enum: null
    range: null
    shape: null
    structure:
    - ParamAttr
descp: Embedding Layer, used to construct a callable object of the Embedding class.
  For specific usage, refer to code examples. It implements the function of the Embedding
  Layer. This layer is used to lookup embeddings vector of ids provided by x . It
  automatically constructs a 2D embedding matrix based on the input num_embeddings
  and embedding_dim.
inputs:
  optional:
  - padding_idx
  - sparse
  - weight_attr
  - name
  required:
  - num_embeddings
  - embedding_dim
