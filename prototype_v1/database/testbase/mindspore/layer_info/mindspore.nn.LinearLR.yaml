api: mindspore.nn.LinearLR(optimizer, start_factor=1.0 / 3, end_factor=1.0, total_iters=5,
  last_epoch=- 1, verbose=False)
descp: 'Decays the learning rate of each parameter group by linearly changing small
  multiplicative factor until the number of epoch reaches a pre-defined milestone:
  total_iters.'
constraints:
  optimizer:
    descp: optimizer (mindspore.nn.optim_ex.Optimizer) – Wrapped optimizer.
    default: null
    dtype:
    - mindspore.nn.optim_ex.optimizer
  start_factor:
    descp: 'start_factor (float, optional) – The number we multiply learning rate
      in the first epoch. The multiplication factor changes towards end_factor in
      the following epochs. Default: 1.0 /3.'
    default: 1/3
    dtype:
    - float
  end_factor:
    descp: 'end_factor (float, optional) – The number we multiply learning rate at
      the end of linear changing process. Default: 1.0.'
    default: 1.0
    dtype:
    - float
  total_iters:
    descp: 'total_iters (int, optional) – The number of iterations that multiplicative
      factor reaches to 1. Default: 5.'
    default: 5
    dtype:
    - int
    structure:
    - single
    range: null
  last_epoch:
    descp: 'last_epoch (int, optional) – The index of the last epoch. Default: -1.'
    default: -1
    dtype:
    - int
    structure:
    - single
    range: null
  verbose:
    descp: 'verbose (bool, optional) – If True, prints a message to stdout for each
      update. Default: False.'
    default: False
    dtype:
    - bool
inputs:
  optional:
  - start_factor
  - end_factor
  - total_iters
  - last_epoch
  - verbose
  required:
  - optimizer
