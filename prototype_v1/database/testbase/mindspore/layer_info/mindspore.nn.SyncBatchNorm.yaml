api: mindspore.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.9, affine=True,
  gamma_init='ones', beta_init='zeros', moving_mean_init='zeros', moving_var_init='ones',
  use_batch_statistics=None, process_groups=None)
descp: Sync Batch Normalization layer over a N-dimension input.
constraints:
  num_features:
    descp: num_features (int) – C from an expected input of size ((N, C, H, W)).
    default: null
    dtype:
    - int
    structure:
    - single
    range: null
  eps:
    descp: 'eps (float) – (epsilon), a value added to the denominator for numerical
      stability. Default: 1e-5 .'
    default: 1e-5
    dtype:
    - float
  momentum:
    descp: 'momentum (float) – A floating hyperparameter of the momentum for the running_mean
      and running_var computation. Default: 0.9 .'
    default: 0.9
    dtype:
    - float
  affine:
    descp: 'affine (bool) – A bool value. When set to True , (gamma) and (beta) can
      be learned. Default: True .'
    default: True
    dtype:
    - bool
  gamma_init:
    descp: 'gamma_init (Union[Tensor, str, Initializer, numbers.Number]) – Initializer
      for the (gamma) weight. The values of str refer to the function initializer
      including ''zeros'' , ''ones'' , ''xavier_uniform'' , ''he_uniform'' , etc.
      Default: ''ones'' .'
    default: ones
    dtype:
    - str
    enum:
    - zeros
    - ones
    - xavier_uniform
    - he_uniform
  beta_init:
    descp: 'beta_init (Union[Tensor, str, Initializer, numbers.Number]) – Initializer
      for the (beta) weight. The values of str refer to the function initializer including
      ''zeros'' , ''ones'' , ''xavier_uniform'' , ''he_uniform'' , etc. Default: ''zeros''
      .'
    default: zeros
    dtype:
    - str
    enum:
    - zeros
    - ones
    - xavier_uniform
    - he_uniform
  moving_mean_init:
    descp: 'moving_mean_init (Union[Tensor, str, Initializer, numbers.Number]) – Initializer
      for the moving mean. The values of str refer to the function initializer including
      ''zeros'' , ''ones'' , ''xavier_uniform'' , ''he_uniform'' , etc. Default: ''zeros''
      .'
    default: zeros
    dtype:
    - str
    enum:
    - zeros
    - ones
    - xavier_uniform
    - he_uniform
  moving_var_init:
    descp: 'moving_var_init (Union[Tensor, str, Initializer, numbers.Number]) – Initializer
      for the moving variance. The values of str refer to the function initializer
      including ''zeros'' , ''ones'' , ''xavier_uniform'' , ''he_uniform'' , etc.
      Default: ''ones'' .'
    default: ones
    dtype:
    - str
    enum:
    - zeros
    - ones
    - xavier_uniform
    - he_uniform
  use_batch_statistics:
    descp: 'use_batch_statistics (bool) – If true , use the mean value and variance
      value of current batch data. If false , use the mean value and variance value
      of specified value. If None , training process will use the mean and variance
      of current batch data and track the running mean and variance, eval process
      will use the running mean and variance. Default: None .'
    default: None
    dtype:
    - bool
  process_groups:
    descp: 'process_groups (list) – A list to divide devices into different sync groups,
      containing N subtraction lists. Each subtraction list contains int numbers identifying
      rank ids which need to be synchronized in the same group. All int values must
      be in [0, rank_size) and different from each other. Default: None , indicating
      synchronization across all devices.'
    default: None
    dtype: null
    structure:
    - list
inputs:
  optional:
  - eps
  - momentum
  - affine
  - gamma_init
  - beta_init
  - moving_mean_init
  - moving_var_init
  - use_batch_statistics
  - process_groups
  required:
  - num_features
