api: torch.nn.NLLLoss(class , weight=None, size_average=None, ignore_index=- 100,
  reduce=None, reduction='mean')
constraints:
  weight:
    descp: a manual rescaling weight given to each class. If given, it has to be a
      Tensor of size C. Otherwise, it is treated as if having all ones.
    dtype:
    - tensor, optional
  size_average:
    descp: Deprecated (see reduction). By default, the losses are averaged over each
      loss element in the batch. Note that for some losses, there are multiple elements
      per sample. If the field size_average is set to False, the losses are instead
      summed for each minibatch. Ignored when reduce is False.
    default: None
    dtype:
    - bool
  ignore_index:
    descp: Specifies a target value that is ignored and does not contribute to the
      input gradient. When size_average is True, the loss is averaged over non-ignored
      targets.
    dtype:
    - int
    structure:
    - single
    shape: null
    range: null
  reduce:
    descp: Deprecated (see reduction). By default, the losses are averaged or summed
      over observations for each minibatch depending on size_average. When reduce
      is False, returns a loss per batch element instead and ignores size_average.
    default: None
    dtype:
    - bool
  reduction:
    descp: 'Specifies the reduction to apply to the output: none | mean | sum. none:
      no reduction will be applied, mean: the weighted mean of the output is taken,
      sum: the output will be summed. Note: size_average and reduce are in the process
      of being deprecated, and in the meantime, specifying either of those two args
      will override reduction.'
    default: mean
    dtype:
    - str
    enum: null
descp: The negative log likelihood loss. It is useful to train a classification problem
  with C classes.
inputs:
  optional:
  - weight
  - size_average
  - ignore_index
  - reduce
  - reduction
  required: []
