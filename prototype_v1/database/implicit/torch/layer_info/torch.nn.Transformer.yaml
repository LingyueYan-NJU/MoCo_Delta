api: torch.nn.Transformer(class , d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6,
  dim_feedforward=2048, dropout=0.1, activation=<function relu>, custom_encoder=None,
  custom_decoder=None, layer_norm_eps=1e-05, batch_first=False, norm_first=False,
  device=None, dtype=None)
constraints:
  d_model:
    descp: the number of expected features in the encoder/decoder inputs (default=512).
    dtype:
    - int
    structure:
    - single
    shape: null
    range: null
  nhead:
    descp: the number of heads in the multiheadattention models (default=8).
    dtype:
    - int
    structure:
    - single
    shape: null
    range: null
  num_encoder_layers:
    descp: the number of sub-encoder-layers in the encoder (default=6).
    dtype:
    - int
    structure:
    - single
    shape: null
    range: null
  num_decoder_layers:
    descp: the number of sub-decoder-layers in the decoder (default=6).
    dtype:
    - int
    structure:
    - single
    shape: null
    range: null
  dim_feedforward:
    descp: the dimension of the feedforward network model (default=2048).
    dtype:
    - int
    structure:
    - single
    shape: null
    range: null
  dropout:
    descp: the dropout value (default=0.1).
    dtype:
    - float
    structure:
    - single
    shape: null
  activation:
    descp: "the activation function of encoder/decoder intermediate layer, can be\
      \ a string (\u201Crelu\u201D or \u201Cgelu\u201D) or a unary callable."
    default: relu
    dtype:
    - str
    - union[str, callable[[tensor], tensor]]
    - union[str, callable[[tensor], tensor]]
    enum: null
  custom_encoder:
    descp: custom encoder (default=None).
    dtype:
    - optional[any]
  custom_decoder:
    descp: custom decoder (default=None).
    dtype:
    - optional[any]
  layer_norm_eps:
    descp: the eps value in layer normalization components (default=1e-5).
    dtype:
    - float
    structure:
    - single
    shape: null
  batch_first:
    descp: If True, then the input and output tensors are provided as (batch, seq,
      feature).
    default: False (seq, batch, feature).
    dtype:
    - bool
  norm_first:
    descp: if True, encoder and decoder layers will perform LayerNorms before other
      attention and feedforward operations, otherwise after.
    default: False (after).
    dtype:
    - bool
descp: "A transformer model. User is able to modify the attributes as needed. The\
  \ architecture is based on the paper \u201CAttention Is All You Need\u201D. Ashish\
  \ Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\
  \ Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances\
  \ in Neural Information Processing Systems, pages 6000-6010."
inputs:
  optional: []
  required:
  - d_model
  - nhead
  - num_encoder_layers
  - num_decoder_layers
  - dim_feedforward
  - dropout
  - activation
  - custom_encoder
  - custom_decoder
  - layer_norm_eps
  - batch_first
  - norm_first
