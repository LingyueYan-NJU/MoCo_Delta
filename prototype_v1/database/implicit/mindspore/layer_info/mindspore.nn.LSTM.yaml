api: mindspore.nn.LSTM(*args, **kwargs)
constraints:
  batch_first:
    default: false
    descp: "batch_first (bool) \u2013 Specifies whether the first dimension of input\
      \ x is batch_size. Default: False ."
    dtype:
    - bool
  bidirectional:
    default: false
    descp: "bidirectional (bool) \u2013 Specifies whether it is a bidirectional LSTM,\
      \ num_directions=2 if bidirectional=True otherwise 1. Default: False ."
    dtype:
    - bool
  dropout:
    default: 0
    descp: "dropout (float, int) \u2013 If not 0, append Dropout layer on the outputs\
      \ of each LSTM layer except the last layer. Default 0 . The range of dropout\
      \ is [0.0, 1.0)."
    dtype:
    - int
    - float
    range: null
    structure:
    - single
  has_bias:
    default: true
    descp: "has_bias (bool) \u2013 Whether the cell has bias b_ih and b_hh. Default:\
      \ True ."
    dtype:
    - bool
  hidden_size:
    default: null
    descp: "hidden_size (int) \u2013 Number of features of hidden layer."
    dtype:
    - int
    range: null
    structure:
    - single
  input_size:
    default: null
    descp: "input_size (int) \u2013 Number of features of input."
    dtype:
    - int
    range: null
    structure:
    - single
  num_layers:
    default: 1
    descp: "num_layers (int) \u2013 Number of layers of stacked LSTM . Default: 1\
      \ ."
    dtype:
    - int
    range: null
    structure:
    - single
descp: Stacked LSTM (Long Short-Term Memory) layers.
inputs:
  optional:
  - num_layers
  - has_bias
  - batch_first
  - dropout
  - bidirectional
  required:
  - input_size
  - hidden_size
