api: mindspore.nn.BCEWithLogitsLoss(reduction='mean', weight=None, pos_weight=None)
constraints:
  pos_weight:
    default: None
    descp: "pos_weight (Tensor, optional) \u2013 A weight of positive examples. Must\
      \ be a vector with length equal to the number of classes. If not None, it must\
      \ be broadcast to a tensor with shape of logits, data type must be float16 or\
      \ float32. Default: None ."
    dtype:
    - tensor
  reduction:
    default: mean
    descp: "reduction (str) \u2013 Type of reduction to be applied to loss. The optional\
      \ values are 'mean' , 'sum' , and 'none' . If 'none' , do not perform reduction.\
      \ Default: 'mean' ."
    dtype:
    - str
    enum:
    - none
    - mean
    - sum
  weight:
    default: None
    descp: "weight (Tensor, optional) \u2013 A rescaling weight applied to the loss\
      \ of each batch element. If not None, it can be broadcast to a tensor with shape\
      \ of logits, data type must be float16 or float32. Default: None ."
    dtype:
    - tensor
descp: Adds sigmoid activation function to input logits, and uses the given logits
  to compute binary cross entropy between the logits and the labels.
inputs:
  optional:
  - reduction
  - weight
  - pos_weight
  required: []
