api: mindspore.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.9, affine=True,
  gamma_init='ones', beta_init='zeros', moving_mean_init='zeros', moving_var_init='ones',
  use_batch_statistics=None, data_format='NCHW')
constraints:
  affine:
    default: true
    descp: "affine (bool) \u2013 A bool value. When set to True , (gamma) and (beta)\
      \ can be learned. Default: True ."
    dtype:
    - bool
  beta_init:
    default: zeros
    descp: "beta_init (Union[Tensor, str, Initializer, numbers.Number]) \u2013 Initializer\
      \ for the (beta) weight. The values of str refer to the function initializer\
      \ including 'zeros' , 'ones' , etc. Default: 'zeros' ."
    dtype:
    - str
    enum:
    - zeros
    - ones
  data_format:
    default: NCHW
    descp: "data_format (str) \u2013 The optional value for data format, is 'NHWC'\
      \ or 'NCHW' . Default: 'NCHW' ."
    dtype:
    - str
    enum:
    - NCHW
    - NHWC
  eps:
    default: 1e-5
    descp: "eps (float) \u2013 (epsilon) added to the denominator for numerical stability.\
      \ Default: 1e-5 ."
    dtype:
    - float
  gamma_init:
    default: ones
    descp: "gamma_init (Union[Tensor, str, Initializer, numbers.Number]) \u2013 Initializer\
      \ for the (gamma) weight. The values of str refer to the function initializer\
      \ including 'zeros' , 'ones' , etc. Default: 'ones' ."
    dtype:
    - str
    enum:
    - zeros
    - ones
  momentum:
    default: 0.9
    descp: "momentum (float) \u2013 A floating hyperparameter of the momentum for\
      \ the running_mean and running_var computation. Default: 0.9 ."
    dtype:
    - float
  moving_mean_init:
    default: zeros
    descp: "moving_mean_init (Union[Tensor, str, Initializer, numbers.Number]) \u2013\
      \ Initializer for the moving mean. The values of str refer to the function initializer\
      \ including 'zeros' , 'ones' , etc. Default: 'zeros' ."
    dtype:
    - str
    enum:
    - zeros
    - ones
  moving_var_init:
    default: ones
    descp: "moving_var_init (Union[Tensor, str, Initializer, numbers.Number]) \u2013\
      \ Initializer for the moving variance. The values of str refer to the function\
      \ initializer including 'zeros' , 'ones' , etc. Default: 'ones' ."
    dtype:
    - str
    enum:
    - zeros
    - ones
  num_features:
    default: null
    descp: "num_features (int) \u2013 The number of channels of the input tensor.\
      \ Expected input size is ((N, C, H, W)), C represents the number of channels."
    dtype:
    - int
    range: null
    structure:
    - single
  use_batch_statistics:
    default: None
    descp: "use_batch_statistics (bool) \u2013 Default: None .  If true , use the\
      \ mean value and variance value of current batch data and track running mean\
      \ and running variance. If false , use the mean value and variance value of\
      \ specified value, and not track statistical value. If None , the use_batch_statistics\
      \ is automatically set to true or false according to the training and evaluation\
      \ mode. During training, the parameter is set to true, and during evaluation,\
      \ the parameter is set to false.  "
    dtype:
    - bool
descp: Batch Normalization is widely used in convolutional networks. This layer applies
  Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel
  dimension) to avoid internal covariate shift.
inputs:
  optional: []
  required: []
