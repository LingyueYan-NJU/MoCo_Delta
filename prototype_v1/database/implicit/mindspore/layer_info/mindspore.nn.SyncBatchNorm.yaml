api: mindspore.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.9, affine=True,
  gamma_init='ones', beta_init='zeros', moving_mean_init='zeros', moving_var_init='ones',
  use_batch_statistics=None, process_groups=None)
constraints:
  affine:
    default: true
    descp: "affine (bool) \u2013 A bool value. When set to True , (gamma) and (beta)\
      \ can be learned. Default: True ."
    dtype:
    - bool
  beta_init:
    default: zeros
    descp: "beta_init (Union[Tensor, str, Initializer, numbers.Number]) \u2013 Initializer\
      \ for the (beta) weight. The values of str refer to the function initializer\
      \ including 'zeros' , 'ones' , 'xavier_uniform' , 'he_uniform' , etc. Default:\
      \ 'zeros' ."
    dtype:
    - str
    enum:
    - zeros
    - ones
    - xavier_uniform
    - he_uniform
  eps:
    default: 1e-5
    descp: "eps (float) \u2013 (epsilon), a value added to the denominator for numerical\
      \ stability. Default: 1e-5 ."
    dtype:
    - float
  gamma_init:
    default: ones
    descp: "gamma_init (Union[Tensor, str, Initializer, numbers.Number]) \u2013 Initializer\
      \ for the (gamma) weight. The values of str refer to the function initializer\
      \ including 'zeros' , 'ones' , 'xavier_uniform' , 'he_uniform' , etc. Default:\
      \ 'ones' ."
    dtype:
    - str
    enum:
    - zeros
    - ones
    - xavier_uniform
    - he_uniform
  momentum:
    default: 0.9
    descp: "momentum (float) \u2013 A floating hyperparameter of the momentum for\
      \ the running_mean and running_var computation. Default: 0.9 ."
    dtype:
    - float
  moving_mean_init:
    default: zeros
    descp: "moving_mean_init (Union[Tensor, str, Initializer, numbers.Number]) \u2013\
      \ Initializer for the moving mean. The values of str refer to the function initializer\
      \ including 'zeros' , 'ones' , 'xavier_uniform' , 'he_uniform' , etc. Default:\
      \ 'zeros' ."
    dtype:
    - str
    enum:
    - zeros
    - ones
    - xavier_uniform
    - he_uniform
  moving_var_init:
    default: ones
    descp: "moving_var_init (Union[Tensor, str, Initializer, numbers.Number]) \u2013\
      \ Initializer for the moving variance. The values of str refer to the function\
      \ initializer including 'zeros' , 'ones' , 'xavier_uniform' , 'he_uniform' ,\
      \ etc. Default: 'ones' ."
    dtype:
    - str
    enum:
    - zeros
    - ones
    - xavier_uniform
    - he_uniform
  num_features:
    default: null
    descp: "num_features (int) \u2013 C from an expected input of size ((N, C, H,\
      \ W))."
    dtype:
    - int
    range: null
    structure:
    - single
  process_groups:
    default: None
    descp: "process_groups (list) \u2013 A list to divide devices into different sync\
      \ groups, containing N subtraction lists. Each subtraction list contains int\
      \ numbers identifying rank ids which need to be synchronized in the same group.\
      \ All int values must be in [0, rank_size) and different from each other. Default:\
      \ None , indicating synchronization across all devices."
    dtype: null
    structure:
    - list
  use_batch_statistics:
    default: None
    descp: "use_batch_statistics (bool) \u2013 If true , use the mean value and variance\
      \ value of current batch data. If false , use the mean value and variance value\
      \ of specified value. If None , training process will use the mean and variance\
      \ of current batch data and track the running mean and variance, eval process\
      \ will use the running mean and variance. Default: None ."
    dtype:
    - bool
descp: Sync Batch Normalization layer over a N-dimension input.
inputs:
  optional:
  - eps
  - momentum
  - affine
  - gamma_init
  - beta_init
  - moving_mean_init
  - moving_var_init
  - use_batch_statistics
  - process_groups
  required:
  - num_features
