PointNet:
  - layer: conv1d
    params:
      in_channels: k
      out_channels: 64
      kernel_size: 1
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 64
    in: x
    out: x
  - layer: conv1d
    params:
      in_channels: 64
      out_channels: 128
      kernel_size: 1
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 128
    in: x
    out: x
  - layer: conv1d
    params:
      in_channels: 128
      out_channels: 1024
      kernel_size: 1
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 1024
    in: x
    out: x
  - layer: max
    params:
      axis: 2
      keepdim: true
    in: x
    out: x
  - layer: reshape
    params:
      shape: [-1, 1024]
    in: x
    out: x
  - layer: linear
    params:
      in_features: 1024
      out_features: 512
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 512
    in: x
    out: x
  - layer: relu
    params: { }
    in: x
    out: x
  - layer: linear
    params:
      in_features: 512
      out_features: 256
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 256
    in: x
    out: x
  - layer: relu
    params: { }
    in: x
    out: x
  - layer: linear
    params:
      in_features: 256
      out_features: k * k
    in: x
    out: x
  - layer: reshape
    params:
      shape: [-1, k, k]
    in: x
    out: x
  - layer: add
    params:
      input: x
      value: identity
    in: x
    out: x
  - layer: eye
    params:
      num_rows: k
      num_columns: k
      dtype: paddle.float32
    in: x
    out: x

pointnet_encoder:
  - layer: transpose
    params:
      perm: [0, 2, 1]
    in: x
    out: x
  - layer: tnet
    in: x
    out: trans_input
  - layer: transpose
    params:
      perm: [0, 2, 1]
    in: x
    out: x
  - layer: slice
    params:
      start: [0, 0, 3]
      end: [B, D, N]
    in: x
    out: feature
  - layer: slice
    params:
      start: [0, 0, 0]
      end: [B, D, 3]
    in: x
    out: x
  - layer: bmm
    in: [x, trans_input]
    out: x
  - layer: concat
    params:
      dim: 2
    in: [x, feature]
    out: x
  - layer: transpose
    params:
      perm: [0, 2, 1]
    in: x
    out: x
  - layer: conv1d
    params:
      in_channels: channel
      out_channels: 64
      kernel_size: 1
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 64
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: conv1d
    params:
      in_channels: 64
      out_channels: 64
      kernel_size: 1
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 64
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: tnet
    in: x
    out: trans_feat
  - layer: transpose
    params:
      perm: [0, 2, 1]
    in: x
    out: x
  - layer: bmm
    in: [x, trans_feat]
    out: x
  - layer: transpose
    params:
      perm: [0, 2, 1]
    in: x
    out: x
  - layer: conv1d
    params:
      in_channels: 64
      out_channels: 64
      kernel_size: 1
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 64
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: conv1d
    params:
      in_channels: 64
      out_channels: 128
      kernel_size: 1
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 128
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: conv1d
    params:
      in_channels: 128
      out_channels: 1024
      kernel_size: 1
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 1024
    in: x
    out: x
  - layer: max
    params:
      axis: 2
      keepdim: true
    in: x
    out: x
  - layer: reshape
    params:
      shape: [-1, 1024]
    in: x
    out: x
  - layer: conditional
    params: {}
    condition: self.global_feat
    true:
      - layer: return
        in: [x, trans_input, trans_feat]
    false:
      - layer: reshape
        params:
          shape: [-1, 1024, 1]
        in: x
        out: x
      - layer: repeat
        params:
          repeats: [1, 1, N]
        in: x
        out: x
      - layer: concat
        params:
          dim: 1
        in: [x, pointfeat]
        out: x
      - layer: return
        in: [x, trans_input, trans_feat]

pointnet_classifier:
  - layer: pointnet_encoder
    params:
      global_feat: true
      input_transform: true
      feature_transform: true
      channel: channel
    in: x
    out: [x, trans_input, trans_feat]
  - layer: linear
    params:
      in_features: 1024
      out_features: 512
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 512
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: linear
    params:
      in_features: 512
      out_features: 256
    in: x
    out: x
  - layer: batchnorm1d
    params:
      num_features: 256
    in: x
    out: x
  - layer: relu
    params: {}
    in: x
    out: x
  - layer: dropout
    params:
      p: 0.3
    in: x
    out: x
  - layer: linear
    params:
      in_features: 256
      out_features: k
    in: x
    out: x
